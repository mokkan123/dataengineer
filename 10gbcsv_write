Hello Everyone,

Thank you all for working hard to bring solutions to the Dev Envoy issues.

To summarize from the INFOP site, the current workaround/solution for non-HTTP/HTTPS services (HDFS, Kafka, and Zookeeper) is as follows:

Please use the provided hostnames and port numbers for these services.

If you experience any issues, feel free to reach out and let us know right away.

Your efforts are much appreciated!




Command to set quota to 75 TB:
hdfs dfsadmin -setSpaceQuota 75t /data/bloombeg

Steps:

Check the current quota (optional, to confirm before/after):

hdfs dfs -count -q -h /data/bloombeg


This will show the current quota usage vs limit.

Update the quota:

hdfs dfsadmin -setSpaceQuota 75t /data/bloombeg


Verify the change:

hdfs dfs -count -q -h /data/bloombeg


The space-quota column should now show 75 T.





Here is a brief summary of the NAS folder configuration across environments.

The NAS folder has been successfully mounted on one of the DEV servers, and the configuration has been prepared so it can be deployed to all other Dremio executor and coordinator nodes.

To expedite this process, I will create a script that:

Installs the required packages (cifs-utils and smbclient)

Configures the mount point

Updates the /etc/fstab file for persistent mounting

A detailed guideline is available here:
ðŸ‘‰ NAS Mount Guide

For the PAT and PROD environments, we first need to validate that:

Dremio servers can access the NAS server

Port 445 (SMB) is open and reachable

Once port access is confirmed and we have the NPID username and password, we can proceed with deployment to PAT and PROD.




Step-by-Step Guide: Setting up a Samba Client on RHEL 7.9
1. Install Required Packages
On RHEL 7.9, you need to install cifs-utils and samba-client to enable SMB/CIFS mounting.

Run the following command:
sudo yum install -y cifs-utils samba-client
2. Test Connectivity with smbclient
List available shares on the server:
smbclient -L //server.example.com -U myuser
If the server requires a domain:
smbclient -L //server.example.com -U MYDOMAIN\\myuser
To connect directly to a share:
smbclient //server.example.com/share -U myuser
3. Create a Mount Point
Create a directory for the SMB share:
sudo mkdir -p /mnt/data
4. Create a Credentials File
For security, store SMB credentials in a file:
sudo mkdir -p /etc/smbcredentials
sudo nano /etc/smbcredentials/myshare.cred
File contents:
username=myuser
password=mypassword
domain=MYDOMAIN
Secure the file:
sudo chmod 600 /etc/smbcredentials/myshare.cred
5. Test Mounting Manually
Run the following command:
sudo mount.cifs //server.example.com/share /mnt/data -o credentials=/etc/smbcredentials/myshare.cred,vers=3.0,sec=ntlmssp
6. Configure /etc/fstab
Edit /etc/fstab to make the mount persistent:
sudo nano /etc/fstab
Add the following line:
//server.example.com/share   /mnt/data   cifs   credentials=/etc/smbcredentials/myshare.cred,vers=3.0,sec=ntlmssp,iocharset=utf8,file_mode=0770,dir_mode=0770   0   0
7. Test the fstab Entry
Run:
sudo mount -a
Verify with:
mount | grep cifs
df -h /mnt/data
8. Troubleshooting
If the mount fails, check connectivity and logs:
nc -zv server.example.com 445
dmesg | tail -n 20
journalctl -xe | grep cifs
Adjust vers= parameter if needed:
vers=3.0 (modern servers)
vers=2.0 or vers=2.1 (older servers)
vers=1.0 (legacy, insecure)


ðŸ”¹ 1. General Format for /etc/fstab
<server/share>   <mount_point>   <fstype>   <options>   <dump>   <pass>


<server/share> â†’ //server/share

<mount_point> â†’ /mnt/data

<fstype> â†’ cifs

<options> â†’ comma-separated list (credentials=..., vers=..., etc.)

<dump> â†’ 0 (donâ€™t dump)

<pass> â†’ 0 (donâ€™t fsck)

ðŸ”¹ 2. Your Example in /etc/fstab

Add this line to /etc/fstab:

# SMB share mount
//server/share   /mnt/data   cifs   credentials=/etc/smbcredentials/myshare.cred,vers=3.0,sec=ntlmssp,iocharset=utf8,file_mode=0770,dir_mode=0770   0   0

ðŸ”¹ 3. Notes

credentials=/etc/smbcredentials/myshare.cred â†’ safer than putting username/password inline.

iocharset=utf8 â†’ avoids issues with filenames (good default).

file_mode and dir_mode â†’ set default permissions for files/dirs. Adjust if needed.

You can test without rebooting:

sudo mount -a


(this will try to mount everything in /etc/fstab).

ðŸ”¹ 4. Verify

Check mounted shares:

mount | grep cifs


âœ… Final Answer (ready-to-paste):

# SMB share mount
//server/share   /mnt/data   cifs   credentials=/etc/smbcredentials/myshare.cred,vers=3.0,sec=ntlmssp,iocharset=utf8,file_mode=0770,dir_mode=0770   0   0


ðŸ‘‰ Do you want me to also show you how to make it mount on demand only (lazy mount) using noauto,x-systemd.automount so it doesnâ€™t hang boot if the server is unreachable?









# SMB share mount
//server/share   /mnt/data   cifs   credentials=/etc/smbcredentials/myshare.cred,vers=3.0,sec=ntlmssp,iocharset=utf8,file_mode=0770,dir_mode=0770   0   0




Common values:

vers=1.0 â†’ SMB1 (old, insecure, but still needed for legacy systems).

vers=2.0 â†’ SMB2.0 (better performance & security than SMB1).

vers=2.1 â†’ SMB2.1 (Windows 7 / Server 2008 R2).

vers=3.0 â†’ SMB3.0 (Windows 8 / Server 2012; adds encryption, better durability).

vers=3.02 â†’ SMB3.02 (Windows 8.1 / Server 2012 R2).

vers=3.1.1 â†’ SMB3.1.1 (Windows 10 / Server 2016; adds pre-auth integrity, improved security).

ðŸ‘‰ If you donâ€™t specify vers=, the kernel tries to auto-negotiate. But for many servers (e.g., Azure Files), you must explicitly specify vers=3.0 or later.

2. sec (Security mode / authentication mechanism)

Purpose: Defines the authentication protocol used between client and server.

Why it matters:
Not all servers support all security modes. Using the wrong one causes Permission denied or mount error(13) failures.

Common values:

sec=ntlm â†’ Uses NTLM (old, weak).

sec=ntlmv2 â†’ Uses NTLMv2 (stronger, recommended).

sec=ntlmssp â†’ NTLMv2 encapsulated in SPNEGO (used by many modern Windows servers).

sec=krb5 â†’ Kerberos authentication (requires Kerberos setup).

sec=krb5i â†’ Kerberos with integrity checking.

sec=krb5p â†’ Kerberos with integrity + encryption.

ðŸ‘‰ By default, mount.cifs usually tries ntlmssp. If your server only supports NTLM or Kerberos, you must override it.

ðŸ”¹ Example command with both options
sudo mount.cifs //server.example.com/share /mnt/share \
  -o username=myuser,domain=MYDOMAIN,vers=3.0,sec=ntlmssp


vers=3.0 â†’ Force SMB3.0

sec=ntlmssp â†’ Use modern NTLMv2 authentication wrapped in SPNEGO


sudo mount -t cifs //nas-server/share /mnt/nas \
  -o username=<your_user>,password=<your_pass>,vers=3.0,iocharset=utf8


sudo mount.cifs //ananthan.ca/data/dremiotest123 /tmp/test123 \
   -o username=<user>,password=<password>,domain=ANANTHAN,vers=3.0,sec=ntlmssp,iocharset=utf8

Absolute Used Capacity = 8%
â†’ This queue is currently using 8% of the whole cluster (its dominant resource share across memory/vcores).

Configured Capacity = 10%
â†’ This queueâ€™s guaranteed share (aka capacity) is 10% of its parent queue. If the parent is root (100%), then its Absolute Capacity is 10% of the whole cluster.

Absolute Configured Max Capacity = 50%
â†’ This queue can grow up to 50% of the whole cluster when others are idle (soft limit). It cannot be scheduled beyond this.



(
echo "To: recipient@example.com"
echo "Subject: Test Email via sendmail"
echo
echo "This is a test email sent using sendmail from the CLI."
) | sendmail -t

sendmail -v recipient@example.com <<EOF
Subject: Test Email from Sendmail Verbose
To: recipient@example.com
From: your_email@example.com

This is the body of the test email.
EOF


(echo "To: recipient@example.com"; echo "From: your_email@example.com"; echo "Subject: Verbose Test Email"; echo ""; echo "Hello, this is a test email.") | sendmail -v -t


from pyspark.sql import SparkSession
import random

# Initialize SparkSession
spark = SparkSession.builder \
    .appName("Generate10GBCSV") \
    .config("spark.sql.shuffle.partitions", "400") \
    .config("spark.executor.instances", "1") \
    .config("spark.executor.cores", "4") \
    .config("spark.executor.memory", "2g") \
    .config("spark.driver.memory", "12") \
    .getOrCreate()

# Function to generate random rows
def generate_row():
    return {
        "id": random.randint(1, 1_000_000),
        "name": f"name_{random.randint(1, 1_000)}",
        "value": random.uniform(1.0, 100.0),
        "category": random.choice(["A", "B", "C", "D"])
    }

# Approximate size of each row in bytes (~100 bytes)
row_size = 100

# Number of rows to generate for ~10GB
num_rows = (10 * 1024**3) // row_size  # 10GB / size per row

# Create RDD and generate DataFrame
data_rdd = spark.sparkContext.parallelize(range(int(num_rows))).map(lambda _: generate_row())
data_df = spark.createDataFrame(data_rdd)

# Output path
output_path = "/opt/data/10gb_data.csv"  # Replace with your desired output path

# Write data to CSV
data_df.write.mode("overwrite").option("header", "true").csv(output_path)

print(f"10GB CSV data written to {output_path}")

# Stop the SparkSession
spark.stop()
