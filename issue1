At the time of the NameNode outage, approximately 10â€“15 DataNodes were marked as stale, reducing the number of available storage targets. During this period, the NameNode logged repeated warnings indicating block placement failures due to unavailable storages. Concurrent delete operations increased metadata activity, leading to a high FSNamesystem write lock queue length. The combined impact of reduced DataNode availability, block placement retries, and elevated metadata delete workload caused severe lock contention, resulting in the NameNode becoming unresponsive and ultimately going down.
